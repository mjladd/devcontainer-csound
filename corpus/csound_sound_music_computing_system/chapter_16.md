# 15. EXPEN: single-scan table-lookup envelope.

15. EXPEN: single-scan table-lookup envelope.
An example from the MUSIC IV manual is shown in listing 1.1, where we can
see the details of the orchestra language. Unit generator output signals are refer-
enced by U names (relating in this case to the order in which they appear), whereas
score parameters and constants are denoted by P and C. This orchestra contains one
simple instrument, WAIL, whose sound is generated by an oscillator (U5) to which
an amplitude envelope (U1) and frequency modulation (U4) are applied. The latter
is a combination of periodic (U2) and random (U3) vibrato signals, mixed together
with the fundamental frequency. The code is Ô¨Ånished with the FINE keyword, after
the maximum number of parallel instances for the WAIL instrument is given.
Listing 1.1 MUSIC IV instrument example [83]
WAIL
INSTR
OSCIL
P4,C3,F1
OSCIL
P6,P7,F1
RANDI P8,P9
ADD3
P5,U2,U3
OSCIL U1,U4,F3
OUT
U5
END
WAIL
COUNT
10
FINE
MUSIC IV was the Ô¨Årst fully Ô¨Çedged computer music programming environ-
ment. The system allowed a good deal of programmability, which is specially true
in terms of synthesis program design. Following its beginnings at Bell Labs, the
software was ported to the IBM computer installation at Princeton University as
MUSIC IVB [105] and then as MUSIC 4BF [53, 111], written in FORTRAN, one
of the Ô¨Årst scientiÔ¨Åc high-level programming languages. An important feature of
this version was that it also used the FORTRAN language for the programming of
instrument deÔ¨Ånitions.
1.2.2 MUSIC V
Mathews‚Äô work at Bell Labs culminated in MUSIC V [84], written in collaboration
with Joan Miller, Richard Moore and Jean-Claude Risset [52]. This was the Ô¨Ånal it-
eration of his MUSIC series, mostly written in the FORTRAN language. This made
it much more portable to other computer installations (including modern operating
systems). It featured the typical three-pass process of MUSIC IV, but with a bet-
ter integration of these operation stages. The orchestra compilation step was now
8
1 Music Programming Systems
combined with pass 3, without the need to generate a separate synthesis program.
FORTRAN conversion subroutines were also integral to the program code. Also
the whole MUSIC V code was written in a single score, which contained both the
note lists and the instruments. Unlike MUSIC IV, there was no maximum instance
count for each instrument. Unit generators could be written either in FORTRAN,
or as separate machine-language subroutines, which could be optimised for speciÔ¨Åc
computers.
MUSIC V provides simple orchestra data types: P (score parameters), V (scalar
values), B (audio signal buffers) and F (function tables). Audio is generated in a
series of sample blocks (or vectors), which by default hold 512 samples. Vector-
based processing became standard in most modern computer music systems (albeit
with some notable options). MUSIC V has been ported to modern systems using the
Gfortran compiler [16]. This software represents a signiÔ¨Åcant milestone in Com-
puter Music, as it was widely used by composers and researchers. In particular, we
should mention that it provided the means through which Risset developed his Cat-
alogue of Computer Synthesized Sounds [108], a fundamental work in digital sound
synthesis. This work stems from his ground-breaking contributions to computer mu-
sic composition, where we see a perfect marriage of artistic and technical craft.
In listing 1.2, we can observe a simple MUSIC V score, implementing the well-
known Risset-Shepard tones [108]. The instrument employs three interpolating os-
cillators (IOSs), generating an amplitude envelope (from a bell function), a fre-
quency envelope (a decaying exponential) and a sine wave controlled by these two
signals (in B3 and B4 respectively). Ten parallel oscillators are started, each with a
10% phase offset relative to the preceding one (tables are 512 samples long). Each
NOT in the score deÔ¨Ånes an oscillator instance, with the Ô¨Årst three parameters (P2,
P3, P4) deÔ¨Åned as start time (0), instrument (1), and duration (14). Oscillator fre-
quencies are deÔ¨Åned by sampling increments (in P6 and P7). The top frequency of
the decaying exponential is P6√ófs/512, where fs is the sampling rate. The ampli-
tude and frequency envelopes have a cycle that lasts for 512/( fs√ó P7).
Pass I of MUSIC V scans the score (which includes both the instrument deÔ¨Åni-
tions and the note list proper) and produces a completely numeric representation of
it. The second pass sorts the note list in time order and applies the CONVT routine,
which can be used to convert frequencies to sampling increments etc. Finally, pass
III schedules the events, calls the unit generators and writes the output.
Listing 1.2 MUSIC V, Risset-Shepard tones, from Risset‚Äôs catalogue [108]
COMMENT -- RISSET CATALOGUE EXAMPLE 513 --
INS 0 1;
IOS P5 P7 B3 F2 P8 ;
IOS P6 P7 B4 F3 P9 ;
IOS B3 B4 B5 F1 P25 ;
OUT B5 B1 ;
END ;
1.2 Early Music Programming Languages
9
GEN 0 2 1 512 1 1 ;
GEN 0 7 2 0 ;
GEN 0 7 3 -10;
NOT 0 1 14 100 50 .0001 0 0 ;
NOT 0 1 14 100 50 .0001 51. 51.1 ;
NOT 0 1 14 100 50 .0001 102.2 102.2 ;
NOT 0 1 14 100 50 .0001 153.3 153.3 ;
NOT 0 1 14 100 50 .0001 204.4 204.4 ;
NOT 0 1 14 100 50 .0001 255.5 255.5 ;
NOT 0 1 14 100 50 .0001 306.6 306.6 ;
NOT 0 1 14 100 50 .0001 357.7 357.7 ;
NOT 0 1 14 100 50 .0001 408.8 408.8 ;
NOT 0 1 14 100 50 .0001 459.9 459.9 ;
TER 16 ;
1.2.3 MUSIC 360
Another important successor to MUSIC IV was MUSIC 360 [124], written at
Princeton University by Barry Vercoe for the large IBM 360 computer [79]. It was
directly derived from MUSIC IVB and MUSIC IVBF, and thus related to those sys-
tems as a MUSIC IV variant. This program was taken to other IBM 360 and 370
installations, and as it was tied in to those large computer installations, it did not suit
smaller institutions, and was not widely available. The development of MUSIC 360
is particularly relevant to Csound, as it is one of its ancestors.
The structure of MUSIC 360 is very similar to its predecessors, utilising the op-
erational principle of three passes discussed above. Here, however, all passes are
combined into a single ‚Äòload module‚Äô (the program) after the orchestra is compiled.
In many ways, MUSIC 360 represented a signiÔ¨Åcant advance with regards to MU-
SIC IV. It allowed any number of parallel instances of instruments to be performed
at the same time. An important innovation seen in this system is the clear deÔ¨Ånition
of the initialisation and performance-time stages, with separate processing stages set
for each. This is a feature that was successfully embraced by subsequent systems,
including Csound. The principle here is that when an instance of an instrument is
going to be run, there are a number of operations that do not to be repeated. These
then are only run in the initialisation phase. For the actual sound to be computed,
the instrument will enter a performance phase, where only the necessary steps to
produce the signal are processed.
For instance, let‚Äôs say we want to notate the pitch of the sound using a system
where 60 is middle C and a change of 1 represents a semitone step (61 is C sharp
etc.). To do this we would need to perform a mathematical operation to convert this
notation into cycles per second (Hz), which is what oscillators expect as a frequency
parameter. This operation does not need to be repeated, it only needs to happen once
10
1 Music Programming Systems
per sound event. So it gets placed in the initialisation stage and its result is then used
at the performance time. Many modern systems employ similar principles in their
design. It is an obvious optimisation that can save a lot of redundant computation.
Another advanced aspect of the language was that arithmetic expressions of up to
12 terms could be employed in the code, with the basic set of operations augmented
by a number of conversion functions. This made the need for different types of
addition operators, and separate multipliers, redundant. Data types included ‚Äòalpha‚Äô-
types, which could hold references to unit generator results (both at I-time and P-
time), K-types, used to hold values from a KDATA statement (which was used to
hold program constants), P-types for note list p-Ô¨Åelds, and U-types, which could
be used to reference unit generator results (as an alternative to ‚Äòalpha‚Äô variables).
There was scoping control, as symbols could be global or local, which included a
facility for accessing variables that were local to a given instrument. The language
also supported conditional control of Ô¨Çow, another advanced feature when compared
to equivalent systems. Some means of extendability were provided by opcodes that
were able to call external FORTRAN subroutines at I- or P-time. In addition, to
facilitate programming a macro substitution mechanism was provided. MUSIC 360
was quite a formidable system, well ahead of its competitors, including MUSIC V.
An example of a simple orchestra program featuring an instrument based on an
oscillator and trapezoidal envelope combination is shown in listing 1.3. In this exam-
ple, we can observe the use of U-types, which refer to the output of unit generators
previously deÔ¨Åned in the code. In this case U1 is a reference to the unit one line
above the current. The PSAVE statement is used to indicate which p-Ô¨Åelds from
score cards will be required in this instrument. The ISIPCH converter is used to
convert ‚Äúoctave.pitch class‚Äù notation into a suitable sampling increment, operating
at initialisation time only. This pitch notation is very useful because it represents
frequencies by an octave number (say 8 is middle-C octave), and a pitch class from
0 to 11 equivalent to note names from C to B in semitones. The term sampling in-
crement is a low-level way of deÔ¨Åning the frequency of an oscillator, and we will
explore its deÔ¨Ånition later in this book.
OSCIL and LINEN are the truncating oscillator and trapezoidal envelope, re-
spectively, used to generate the audio, the oscillator depending on function table 1,
which is deÔ¨Åned as a score statement. The syntax is very close to classic Csound
code (as we will see later in this book), and unit generators are commonly known
here as opcodes.
Listing 1.3 MUSIC 360 instrument example [124]
PRINT NOGEN
ORCH
DECLARE SR=10000
SIMPL
INSTR
1
PSAVE (3,5)
ISIPCH P5
OSCIL P4,U1,1
1.2 Early Music Programming Languages
11
LINEN U1,.03,P3,.06
OUT U1
ENDIN
ENDORCH
END
1.2.4 MUSIC 11
MUSIC 11 [125], a version of the MUSIC 360 system for the smaller DEC PDP-11
minicomputer [126], was introduced by Barry Vercoe at the MIT Experimental Mu-
sic Studio. As the PDP 11‚Äôs popularity grew in the 1970s, and with the introduction
of the UNIX operating system, the program was used at various institutions both in
the USA and elsewhere for over two decades. Not only were many of the innovative
features of MUSIC 360 carried over to the new system, but also important concepts
were pioneered here.
One of the main design aspects Ô¨Årst introduced in MUSIC 11 was the concept
of control (k-) and audio (a-) computation rates. This is a further reÔ¨Ånement of the
initialisation- and performance-time optimisation principle. This made the system
the most computationally efÔ¨Åcient software for audio synthesis of its time. It es-
tablished the main operation principles of the orchestra which divides instrument
action times into initialisation and two performance-time rates, which was realised
in the three basic data types: i, k (control) and a (audio). Global, local and temporary
variables were available (marked as g, l or t).
The control/audio rate mechanism is based on the principle that some signals do
not need to be computed as often as others. For instance, envelopes vary much more
slowly than actual audio signals, and thus do not require to be updated as often.
Sound is computed at a very fast rate (sr, the sampling rate), which often involves
periods of a fraction of a millisecond. Control signals in many situations do not
require that precision, and can be calculated maybe up to one hundred times more
slowly.
Listing 1.4 shows a version of the MUSIC 360 example, now in MUSIC 11
form. Although there are many similarities, some fundamental differences have been
introduced in the language. The header declaration now includes the deÔ¨Ånition of
a control rate (kr) and the audio block size (the ratio sr
kr, ksmps), as well as the
number of output channels to be used (nchnls). The presence of the ksmps parameter
indicates explicitly that computation of audio signals is now performed in chunks
of this size. We will explore this concept in detail in the next chapter, and also
throughout this book.
The type system has been simpliÔ¨Åed; we observe the presence of the k- and a-
type variables, which have now been deÔ¨Åned to hold signals (and not just references
to unit generator outputs) of control and audio forms, respectively. Also, taking
advantage of the introduction of the control rate concept, the oscillator and envelope
have had their positions exchanged in the synthesis graph: the envelope is now a
12
1 Music Programming Systems
control signal generator, rather than an amplitude processor, so the instrument can
be run more efÔ¨Åciently.
Listing 1.4 MUSIC 11 instrument example
sr = 10000
kr = 100
ksmps = 100
nchnls = 1
instr 1
k1
linen p4,.03, p3,.06
a1
oscil
k1, cpspch(p5), 1
out a1
endin
With the introduction of the concept of control rate two issues arise. Firstly, con-
trol signals are liable to produce audio artefacts such as amplitude envelope zipper
noise, which are caused by the staircase nature of these signals, introducing dis-
continuities in the audio output waveform (and a form of aliasing that results in
wideband noise). Secondly, score events are quantised at the control rate, which can
affect the timing precision in some situations. To mitigate these effects, a balance
between efÔ¨Åciency and precision needs to be reached, where the ratio between au-
dio and control rates is small enough to prevent poor results, but high enough to be
efÔ¨Åcient.
1.3 Csound
Csound1 is possibly the longest-running heir to these early MUSIC N systems. It
was developed in the 1980s, alongside similar systems, such as Cmusic [90] and
M4C [7], and Cmix [101]. All of these were developed using the C language, which
at the time became the standard for systems implementation. Csound developed be-
yond its original design into a much larger and multi-functional music programming
environment, with the advent of version 5 in 2006, and version 6 in 2013. The full
Csound ascendancy is shown in Fig. 1.1 with its approximate dates.
Csound came to light at the MIT Electronic Music Studio in 1986 (MIT-EMS
Csound), as a C-language port of MUSIC 11. It inherited many aspects of its parent,
but now integrating the orchestra compiler and loader into a single program. The
original mit-ems Csound was based on three separate commands, scsort, csound
and perf. The Ô¨Årst command would sort the score; the second would compile and
1 Despite the different ways in which its name is written down in various places, there is only
one correct form: capital ‚ÄòC‚Äô followed by lowercase ‚Äòsound‚Äô. A fully lowercase variant csound is
possible, but only when referring to its command-line frontend (see Chapter 2).
1.3 Csound
13
MUSIC IV
1963
-MUSIC 360
1968
-MUSIC 11
1978
-Csound (MIT-EMS)
1986
?
Csound 3-4 (Bath)
1993
?
Csound 5
2006
?
Csound 6
2013
Fig. 1.1 The Csound family tree, from MUSIC IV through to the Ô¨Årst release of the MIT-EMS
Csound in 1986, and the further versions culminating in its current release
load the orchestra, and run the sorted score on it. The third command was just a
convenient tool that called scsort and csound in a sequence.
Csound was originally a very faithful port of MUSIC 11, so much so that even
today many programs for that language can still be run on modern versions of the
system (the code in listing 1.4 runs perfectly in Csound). Some small differences
existed in terms of a collection of new opcodes, and the removal of some others.
Also, the separation between temporary and local variables was removed in Csound,
and a means of extending the language with new C-code opcodes was provided.
However, beyond these small differences, the central concepts were shared between
the systems.
In the 1990s, the centre of development of Csound moved from MIT to the Uni-
versity of Bath. Real-time operation had been introduced to the system [129] in the
MIT-EMS version. From this, the system developed into an ofÔ¨Çine composition and
real-time synthesis language with widespread applications explored in [15]. The
program was also ported to PC-DOS, also with real-time audio via soundblaster
soundcards. Separately, at Mills College, a version of the system for the Macintosh
platform was developed [54].2 By the end of the 1990s, the system had been ported
to almost all modern general-purpose computing platforms.
In a separate development, Csound was also ported to run on custom DSP hard-
ware, in a closed-source version designated extended Csound [127]. This version
eventually became part of a commercial project of Analog Devices Inc., to supply
simple synthesizers for embedded applications [128]. Meanwhile, a large interna-
tional developer community was involved in expanding the open-source system,
which eventually came under the Lesser GNU Public License (and thus Free soft-
ware). Many new unit generators were developed for it, culminating in the Csound
2 An earlier port of Csound for the Mac had also been made available from MIT using the original
UNIX sources modiÔ¨Åed for the THINK C compiler.
14
1 Music Programming Systems
4.23 version in 2002. The consensus among the community was that the system
required a major re-engineering to be able to move forward. A code freeze was
established so that the new Csound 5 system could be developed.
1.3.1 Csound 5
Csound 5 was developed with the main goal of providing a clean, re-engineered sys-
tem that would expose much of its internal operation, moving away from the orig-
inal monolithic program design that characterised its earlier versions [39]. It was
launched in 2006, twenty years after the Ô¨Årst MIT-EMS release in 1986. From a lan-
guage perspective, there were a few signiÔ¨Åcant changes from the original Csound,
which brought more Ô¨Çexibility to programming. A plug-in mechanism made it sim-
pler to extend the system with new unit generators, utilities and function table gen-
erators. Programmable graphical user interfaces (GUIs) were incorporated into the
language. User-deÔ¨Åned unit generators were introduced, providing further facilities
for structuring the code.
A signiÔ¨Åcant innovation in version 5 is the presence of an Application Program-
ming Interface (API), which allows a lower-level control of system operation. The
API made it possible to create Csound-based applications with a variety of program-
ming languages, leading to the development of various third-party host programs.
It was now much easier to port it to mobile operating systems [135]), to use it as
a plug-in for Digital Audio Workstations (DAWs), and to create custom solutions
using Csound as the audio engine.
1.3.2 Csound 6
The next major version of the system, Csound 6, was Ô¨Årst released in 2013. The code
was again considerably reorganised, and a new language parser was introduced.
This is the part of the system that translates the code text into an internal format that
can be used by the compiler to create new instruments. The new parser allowed a
much simpler means of extending and modifying the language, so a number of new
facilities for the programmer were also introduced.
The compiler was signiÔ¨Åcantly modiÔ¨Åed allowing it to operate in an on-the-Ô¨Çy
mode, adding new instruments on demand to a running system. Such changes were
also reÔ¨Çected in a newly designed API, which gave developers increased Ô¨Çexibility
and new possibilities. Alongside these improvements, ports of the system to new
platforms continued, with the addition of support for web-based applications and
embedded systems.
As we have seen in this introduction to music programming systems, Csound Ô¨Åts
very well the description of a software package for general-purpose music making.
However, a more complete picture of what it is today goes beyond this simple def-
1.3 Csound
15
inition. In fact, it depends on how a user approaches this software. At the highest
level, we can think of it as a synthesiser, or as a sound processor. Computer musi-
cians might look at it as a software package that allows us to use the computer to
manipulate sound programmatically.
Software developers, on the other hand, will use Csound as an audio engine, a
system component that will provide all the services that are needed to add sound
to an application. They will use it by embedding it in their software, which can be
done with full control over its operation. So, depending on the perspective, Csound
can be a music program, a programming language or a software library.
Figure 1.2 demonstrates these ideas. At the top, we have the level of the music
application, where Csound is presented in pre-programmed, pre-packaged forms,
with Ô¨Åxed instruments that expose some of their parameters for the user to manipu-
late. This is the case of the various Csound-based apps that exist for mobile, web and
desktop platforms. The next level is the traditional place where music programming
systems reside, where musicians, composers and researchers employ the system by
developing new instruments and means of controlling them. Finally, at the lowest
level, we have Csound as a programming library, the audio engine that developers
(and musicians, researchers, etc. working on application programming) use in their
projects.
Music Application
general users

?
Music Programming Language
musicians, researchers

?
Audio Engine
developers

Fig. 1.2 The three system levels in Csound: at the top, we have music applications (Csound-based
apps for mobile, web and desktop platforms); the middle level is represented by the music pro-
gramming system; and the lowest level is that of Csound as a programming library
1.3.3 Compatibility and Preservation
During its thirty-odd years of development, Csound has been gifted a signiÔ¨Åcant
number of contributions from a world-wide computer music community. An explicit
rule has been followed by developers that new versions of Csound should always
be backwards-compatible. So this means that any changes to the language or the
16
1 Music Programming Systems
system can provide new features and facilities, but will not prevent code designed
for the MIT-EMS Csound from running in the latest version. There is a signiÔ¨Åcant
responsibility on the development team to ensure that the preservation of music
made with the software is guaranteed. This approach has enabled even some music
made with MUSIC 360 and many MUSIC 11 pieces to be rendered in Csound 6.
The backwards-compatibility principle has a downside. While many of the con-
tributions to the system have had a long-lasting impact, a few were less successful.
For instance, some of these were introduced to solve a short-term issue, without a
thorough assessment of their implications, introducing less desirable features. Some
of these cannot be easily eliminated as part of the evolution of the software, as it is
not possible to know whether they have not been used in any work that we want
to preserve. Hopefully, this issue is not signiÔ¨Åcant, as through education and doc-
umentation we can direct the user to the most up-to-date approaches, and mark as
deprecated the less successful legacy elements in the system. Also, since the devel-
opment of Csound 5, there has been an intense effort to think about the implications
of new features and components. This has led to a more cohesive development,
which has mostly eliminated problems with unwanted components.
1.4 Conclusions
In this chapter, we have introduced the concept of music programming systems, and
examined the history of their development leading to the appearance of Csound.
We have seen how the early music languages evolved from the Ô¨Årst direct synthesis
programs by Max Mathews into MUSIC III and MUSIC IV, which were the model
for later systems. Csound itself was the culmination of the developments of MUSIC
360 and MUSIC 11, which were created for speciÔ¨Åc computers. Other classic sys-
tems of note were MUSIC V, written in FORTRAN, which inÔ¨Çuenced the design of
Cmusic, and MUSIC 4C. With the development of computer technology, we also
saw the appearance of systems that were directed explicitly at real-time operation,
which all of the earlier software could not achieve.
Alongside this survey, we have also introduced some of the key principles that are
involved in this technology: computer instruments, numeric scores, function tables,
compilers, data types, initialisation and performance times, computation rates etc.
These will be followed up and explored in further detail in the following chapters of
this book.
Complementing this discussion, the chapter also detailed the main characteristics
of the current Csound system, providing an overview of the ways it can be employed
in computer applications. We have shown that there are many ways to ‚Äòattack‚Äô the
complexity that it presents to the user, from high to low levels of programming. In
this book, we will try to provide a glimpse of all of these levels of operation, while
concentrating on the middle-ground approach of music programming through an
emphasis on computer music composition.