# 3. Adaptive parametric equalizer

3. Adaptive parametric equalizer
The autolevel effect measures the input level and compares this to a desired (tar-
get) level, then calculates a gain factor as the ratio between the two. Gain adjustment
is bypassed if the input level is below a certain threshold (i.e. the background noise
level). The gain factor is limited to a maximum value, and the rate of change for the
gain factor is ﬁltered so as to avoid abrupt glitches.
Listing 18.1 Autolevel effect, trying to maintain a constant output signal level, excluding sounds
below the noise threshold
kRefLevel = ampdbfs(-10)
kLevelRate = 10
kMaxLevelFact = 10
kLowThreshold = ampdbfs(-25)
krmsOut init 1
kLevel init 1
aLeve init 1
krmsIn rms ain
kLevel divz kRefLevel, krmsIn, 1
kLevel = (krmsIn < kLowThreshold ? 1 : kLevel)
kLevel limit kLevel, 0, kMaxLevelFact
kLevel tonek kLevel, kLevelRate
aLevel interp kLevel*0.5
aout = ain * aLevel
In an audio signal generated by feedback from speaker to microphone, we will
have a set of clearly deﬁned partials and these will generally be the spectral com-
ponents with the highest energy. The adaptive spectral equaliser uses an FFT (or
18.2 Feedback-Processing Techniques
445
more speciﬁcally a streaming phase vocoder, pvs opcodes) to analyze the spectrum,
and then selectively lower the amplitudes of the loudest frequencies. This is done by
creating a masking table, where each table index corresponds to a speciﬁc frequency
(a bin of the pvs signal). The masking table is initially ﬁlled with all 1’s. When we
want to lower the energy of theNstrongest spectral components, we iterate over the
set of binsNtimes, each time looking for the bin with the highest energy and setting
the masking table to zero for the index of the strongest component. We can then use
the table as an adjustable spectral mask by means of the pvsmaska opcode, adjust-
ing the amount of gain reduction for the selected bands with the kdepth parameter.
To be dynamically updated the spectral proﬁle, we run this process periodically at
a selectable update rate. Each time we have an updated spectral proﬁle, we use the
ftmorf opcode to gradually change from the old proﬁle to the new one.
Listing 18.2 Global ftables for the adaptive spectral equalizer
gifftsize = 256
giFftTabSize = (gifftsize / 2)+1
; amplitudes and frequencies for the pvs bins
gifna ftgen 0,0,giFftTabSize,7,0,giFftTabSize,0
gifnf ftgen 0,0,giFftTabSize,7,0,giFftTabSize,0
; all 1’s
gi1 ftgen 0,0,giFftTabSize,7,1,giFftTabSize,1
; tables for storing and morphing spectral masks
gifnaMod ftgen 0,0,giFftTabSize,7,0,giFftTabSize,0
gifnaMod1 ftgen 0,0,giFftTabSize,7,0,giFftTabSize,0
gifnaMod2 ftgen 0,0,giFftTabSize,7,0,giFftTabSize,0
gifnaMorf ftgen 0,0,4,-2,gifnaMod2,gifnaMod1,
gifnaMod2,gifnaMod1
Listing 18.3 Adaptive spectral equalizer instrument code
fsin pvsanal ain,gifftsize,gifftsize/4,gifftsize,1
kflag pvsftw fsin,gifna,gifnf
kpvsNumBands = 4
kpvsAmpMod = 1
kpvsResponseTime = 1
kpvsSmoothTime = 0.5
kpvsResponseCps divz 1,kpvsResponseTime,1
kmetro metro kpvsResponseCps
kdoflag init 0
kdoflag = kdoflag + kmetro
kswitch init 1 ; count 1,2,1,2
kswitch = (kswitch == 1 ? \
kswitch + kmetro :
kswitch - kmetro)
446
18 Øyvind Brandtsegg: Feedback Piece
; copy pvs data from table to array
; modify amplitude of single bin
; repeat the above N number of times
if (kdoflag > 0) && (kflag > 0) then
kArr2[] init giFftTabSize-2
kArrM[] init giFftTabSize-2
copyf2array kArr2, gifna
copyf2array kArrM, gi1
kcount = 0
process:
kMa, kMaxIndx maxarray kArr2
kArr2[kMaxIndx] = 0
kArrM[kMaxIndx] = 0
kcount = kcount + 1
if kcount < kpvsNumBands then
kgoto process
endif
if kswitch == 1 then
copya2ftab kArrM, gifnaMod2
reinit morftable
else ; (if switch is 2)
copya2ftab kArrM, gifnaMod1
reinit morftable
endif
kdoflag = 0
endif
morftable:
iswitch = i(kswitch)
kinterp = kpvsSmoothTime*kpvsResponseTime
ikinterp = i(kinterp)
kmorfindx linseg iswitch, ikinterp, iswitch+1,
1, iswitch+1
ftmorf kmorfindx, gifnaMorf, gifnaMod
rireturn
; modify and resynth
fsout pvsmaska fsin, gifnaMod, kpvsAmpMod
aout pvsynth fsout
The adaptive spectral effect can be thought of as an equaliser with a large number
of static and narrow bands. It works quite effectively to reduce feedback and the ad-
justable response time allows a certain room for feedback to build up before being
18.3 Coloring Effects
447
damped. In addition to this, a parametric equaliser coupled with a pitch tracker is
used as an alternative and complementary means of reducing feedback. We could
use the term “homing ﬁlter” to describe its behaviour. No claims are made about the
efﬁciency and transparency of this method for any other purposes than use in this
composition. The frequency of a band-stop ﬁlter is controlled by the pitch tracker.
If the pitch tracker output jumps to a new frequency, the band-stop ﬁlter slowly
approaches this frequency, possibly removing components that did not create feed-
back, as it travels across the frequency range to close in on the target frequency. In
this respect it is in no way considered a “correct” feedback reducer, but acts as part
of the complex but deterministic audio system for the composition.
Listing 18.4 Adaptive parametric equalizer. One band is shown, it is commonly used with at least
three of these in series
kFiltFreq chnget "HomingRate"
kStrength1 chnget "FilterAmount1"
kFiltQ1 chnget "FilterQ1"
kamp rms a1
acps,alock plltrack a1, 0.3, 20, 0.33, 20, 2000,
ampdbfs(-70)
kcps downsamp acps
kcps limit kcps, 20, 2000
kcps tonek kcps, kFiltFreq
kamp tonek kamp*5, kFiltFreq
kdamp = 1-(kamp*kStrength1)
kgain limit kdamp, 0.01, 1
a2 pareq a1, kcps, kgain, kFiltQ1
18.3 Coloring Effects
To enhance and prolong the feedback effects, a simple stereo delay with crossfeed
between channels is used. The piece is played with two microphones, and each mi-
crophone is mainly routed to its own output channel. The crossfeed in the delay
processing allows a certain amount of feedback from one microphone to bleed into
the signal chain of the other microphone, creating a more enveloping spatial image.
Granular processing with the Hadron Particle Synthesizer1 is used to extend the
sonic palette with noisy, intermittent, and pitch-shifted textures. Spectral-panning
techniques are also used to spread the frequency components of each signal chain to
several audio outputs, inspired by Peiman Koshravi’s circumspectral panning tech-
niques [58] which he in turn picked up from Denis Smalley [117].
1 www.partikkelaudio.com
448
18 Øyvind Brandtsegg: Feedback Piece
Listing 18.5 Spectral panner
sr = 44100
ksmps = 256
nchnls = 2
0dbfs=1
giSine ftgen
0, 0, 65536, 10, 1
gifftsize = 2048
iNumBins = gifftsize/2
; tables to spectral panning shapes
gipantab1 ftgen 0,0,iNumBins,7,0,iNumBins, 0
gipantab2 ftgen 0,0,iNumBins,7,1,iNumBins, 1
; spectral points (anchors) for panning curve
ifq1 = 120
iHzPrBin = sr/iNumBins ; Hz per bin
iBin1 = round(ifq1/iHzPrBin) ; bin number for this fq
iBin2 = round(ifq1*2/iHzPrBin)
iBin3 = round(ifq1*4/iHzPrBin)
iBin4 = round(ifq1*8/iHzPrBin)
iBin5 = round(ifq1*16/iHzPrBin)
iBin6 = round(ifq1*32/iHzPrBin)
iBin7 = round(ifq1*64/iHzPrBin)
iBin8 = round(ifq1*128/iHzPrBin)
; spectral panning shape A
gipantab1A ftgen 0,0,iNumBins,27, 0, 0, iBin1, 0, iBin8,
1, iNumBins-1, 0
; complementary spectral panning shape
gipantab2A ftgen 0,0,iNumBins,27, 0, 0, iBin1, 1, iBin8,
0, iNumBins-1, 1
; shape B
gipantab1B ftgen 0,0,iNumBins,27, 0, 0, iBin1, 0, iBin5,
1, iBin8, 0, iNumBins-1, 1
gipantab2B ftgen 0,0,iNumBins,27, 0, 0, iBin1, 1, iBin5,
0, iBin8, 1, iNumBins-1, 0
; shape C
gipantab1C ftgen 0,0,iNumBins,27, 0, 0, iBin1, 0, iBin4,
1, iBin7, 0, iNumBins-1, 0
gipantab2C ftgen 0,0,iNumBins,27, 0, 0, iBin1, 1, iBin4,
0, iBin7, 1, iNumBins-1, 1
18.3 Coloring Effects
449
; shape D
gipantab1D ftgen 0,0,iNumBins,27, 0, 0, iBin1, 0, iBin3,
1, iBin5, 0, iBin7, 1, iNumBins-1, 1
gipantab2D ftgen 0,0,iNumBins,27, 0, 0, iBin1, 1, iBin3,
0, iBin5, 1, iBin7, 0, iNumBins-1, 0
; morphing between shapes
gimorftable1 ftgen 0,0,4,-2, gipantab1A, gipantab1B,
gipantab1C, gipantab1D
gimorftable2 ftgen 0,0,4,-2, gipantab2A, gipantab2B,
gipantab2C, gipantab2D
instr 1
; spectral panning
kDepth chnget "Depth"
kMorph chnget "Morph"
kMorphLfoAmp chnget "MorphLfoAmp"
kMorphLfoFreq chnget "MorphLfoFreq"
kLFO poscil 0.5, kMorphLfoFreq, giSine
kLFO = (kLFO + 0.5)*kMorphLfoAmp
kMorph = kMorph+kLFO
kMorph limit kMorph, 0, 3
ain inch 1
fsin pvsanal ain,gifftsize,gifftsize/3,gifftsize,0
fin1 pvsmix fsin,fsin ; just a simple copy
fin2 pvsmix fsin,fsin
; morph between spectral panning shapes
ftmorf kMorph, gimorftable1, gipantab1
ftmorf kMorph, gimorftable2, gipantab2
fin1 pvsmaska fin1, gipantab2, kDepth
fin2 pvsmaska fin2, gipantab1, kDepth
a1 pvsynth fin1
a2 pvsynth fin2
; try to make up gain
a1 = a1*ampdbfs(kDepth*3)
a2 = a2*ampdbfs(kDepth*3)
outs a1, a2
endin
450
18 Øyvind Brandtsegg: Feedback Piece
18.4 Hosting and Interfacing
The processors are compiled as VST plug-ins using Cabbage, so as to be used with
any VST host. I ﬁnd it quite useful to rely on one of the standard DAWs or VST
hosts to provide “bread and butter” functionality like signal i/o, metering, routing,
and mixing. I have been using Reaper as the main host for this purpose. For prac-
tical purposes related to the full live rig (enabling several other pieces and impro-
visations), I have split the processing load between two computers, sending audio
via ADAT between the two machines (Fig. 18.1). This allows the use of large audio
buffer sizes for relaxed processing on the second computer while retaining the possi-
bility for small buffer sizes and low latency on the primary computer. The delays and
granular effects for the feedback piece are calculated on the second computer. The
effects automation for the feedback piece was originally entered as an automation
track in AudioMulch, and due to practical issues related to exporting said automa-
tion tracks, I have continued using that host for the automated effects in this piece.
The adaptive ﬁlters and other feedback-conditioning processes run under Reaper on
the ﬁrst computer. If I were making a technical rig for this piece only, it would be
quite possible to run it all on one single computer.
Fig. 18.1 Signal ﬂow between the two computers, also showing the patching of effects within
AudioMulch
18.5 Automation and Composed Form
The main form of the piece can be split into two sections, where the ﬁrst one is free
and the second is automated. Automation in this context relates to a timed script for
changes to the effect parameters, gradually changing the instrument’s timbre over
18.6 Spatial and Performative Considerations
451
time. The actual content and sonic gestures for the ﬁrst section are not notated, and
are indeed free to be performed differently in each performance of the piece. How-
ever, when I play it, I usually try to make two or three very similar sounds in the
beginning of the piece, making the sound almost completely stop between each pair
of gestures. This also serves as a way of sharing with the audience how this instru-
ment works, showing the relationship between gestures and resulting sound. I then
go on to vary the gestures and so develop nuances of the timbre. The free section has
an unspeciﬁed duration, but usually continues until the sonic material has been suf-
ﬁciently exposed. The automated part is then started by means of a trigger signal on
a MIDI pedal, sending a play message to the automation host (see Fig. 18.2). Dur-
ing the automated part, the balance between a relatively clean feedback signal and a
heavily processed signal is gradually changed. Automation envelopes for the param-
eters are shown in Fig. 18.3. The granular effects processing signiﬁcantly changes
the recognisable harmonic feedback tone into a scattering noise based texture. Parts
of the granular processing are controlled by pitch tracking, so there is an additional
layer of feedback between the pitch of the sound in the room and the speciﬁc param-
eters of the granular processing in Hadron, which again is sent out into the room.
The automated section concludes by returning the balance of effects processing to a
situation where the feedback signal is relatively clean. Performance-wise, I usually
try to conclude the piece with a few repetitive sounds/gestures as a means of making
a connection to the beginning, and reminding the listener of the basic premise for
the piece.
Fig. 18.2 Overall blockwise form
18.6 Spatial and Performative Considerations
The performer of the piece holds the two directional microphones, usually with
wireless transmitters so as to increase mobility and reduce the clutter of cable when
moving around the space. Microphone gain is controlled by means of EMG (muscle
activity) sensors. When the performer tenses the arm muscles, the signal level is in-
creased. This allows for expressive control, and is also a reasonable safety measure
to ensure the feedback does not get out of hand (pun intended). An additional “free
gift” of this performance setup is that the piece actually requires physical effort to
perform. This is in contrast to many other forms of electronic music performance,
where there is no direct relation between the physical effort and the produced sound.
452
18 Øyvind Brandtsegg: Feedback Piece
Fig. 18.3 Effects parameter automation in AudioMulch
From experience I also know that this can lend a certain dramatic aspect to the per-
formance situation. The EMG system I personally use is a BodySynth built by Ed
Severinghaus in the 1990s, but it would also be possible to make a similar system
using an Arduino board with EMG sensors and a wireless expansion board.
An interesting aspect of the sound-producing mechanism created by this system is
the complex relationship governing the availability and resonance of different fun-
damental frequencies. The distance between microphone and speaker effectively
controls the potential fundamental frequencies, as a function of distance and the
speed of sound. In addition, the resonances of the room allow some frequencies
more aptitude for feedback, and these resonances change with the performer’s posi-
tion in the room. The position of the microphone in relation to the separate compo-
nents of the speaker also greatly affects the feedback potential. The treble drivers are
sometimes quite directional, allowing for precise control of feedback in the higher
spectral register. One can also physically intervene in the feedback path by putting
a hand between the speaker and the microphone, and in this manner balance the
amount of high frequency content in the feedback timbre (see Fig. 18.4). Similarly,
some speaker types radiate bass frequencies via backwards facing bass ports, so go-
ing up close to a speaker and “hugging it” may both mufﬂe some direct sound and
also put the microphones in as position where deeper frequencies are more pregnant.
The software components controlling the feedback loop will also affect the spectral
potential. Some of the components are speciﬁcally designed to reduce feedback,
and others are designed to increase or maintain the feedback potential. The adaptive
ﬁlters will continuously change in relation to the spectral content of the incoming
18.6 Spatial and Performative Considerations
453
sound, so it may not be possible to recreate the exact same sound with the same per-
formative gesture at different points in time. The dynamic nature of the instrument
thus may seem to create a very difﬁcult situation for the performer, but keep in mind
that there is nothing random in the signal chain. Even if it is governed by complex
adaptive processes, it is completely deterministic, and thus ultimately controllable.
Fig. 18.4 Using a hand between speaker and microphone to obstruct the feedback path, affecting
the spectral balance of the feedback signal
