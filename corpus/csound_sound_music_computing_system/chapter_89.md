# 6. Hop the window position by N

6. Hop the window position by N
o samples, where o is the number of overlapped
frames.
The full listing of a PV analysis UDO is shown in listing 14.3. This is designed to
work with the data generated by the PVA opcode. This code also requires the hopsize
to be an integral multiple of ksmps to allow the shiftout opcode to perform the
overlap-add operation correctly.
Listing 14.3 Phase vocoder synthesis opcode
/**************************************************
asig PVS kMags[],kFreqs[],kflg,isize,ihop
kMags[] - input magnitudes
kFreqs[] - input frequencies
kflg - new frame flag (1=process new frame)
isize - DFT size
ihop - hopsize
**************************************************/
opcode PVS,a,k[]k[]kii
kMags[],kFr[],kfl,isize,ihop xin
iolaps init isize/ihop
ifac = ihop*2*$M_PI/sr;
iscal = sr/isize
krow init 0
kOla[] init isize
kOut[][] init iolaps,isize
kPhs[] init isize/2+1
if kfl == 1 then
kk = 0
while kk < isize/2 do
310
14 Spectral Processing
kFr[kk] = (kFr[kk] - kk*iscal)*ifac
kk += 1
od
kPhs = kFr + kPhs
kSpec[] pol2rect kMags,kPhs
kRow[] rifft kSpec
kWin[] window kRow, -krow*ihop
kOut setrow kWin, krow
kOla = 0
kk = 0
until kk == iolaps do
kRow getrow kOut, kk
kOla = kOla + kRow
kk += 1
od
krow = (krow+1)%iolaps
endif
xout shiftout(kOla)/iolaps
endop
These two opcodes implement streaming PV analysis and synthesis, to which
modiﬁcations can be made on the ﬂy. They demonstrate the process from ﬁrst prin-
ciples, for didactical purposes mostly. For practical applications, users should em-
ploy the internal opcodes pvsanal and pvsynth, which are equivalent, but are
more efﬁcient and convenient:
fsig
pvsanal asig,isize,ihop,iwinsize,iwintype
asig
pvsynth fsig
The input parameters to the analysis are input signal, DFT size, hop size, win-
dow size and window type. Window size can be larger than DFT size, but in most
applications it is the same. There are a variety of available window shapes, the most
commonly used being the Hanning, which is type 1. The analysis data is carried in
a spectral type (f-sig), which conveniently wraps the spectral data, its description
(DFT size etc.) and a framecount to allow other opcodes to operate correctly at the
PV analysis rate. Streaming spectral signals can then be synthesised with pvsynth.
There are no limitations as to the size of the hop with these opcodes. However, if the
hopsize is less than ksmps, analysis and resynthesis is done sample by sample using
the sliding DFT algorithm (which can be very expensive in computational terms).
The PV algorithm is also used in other Csound opcodes, such as temposcal and
mincer, which can be used for timescaling and pitch-shifting effects. The Csound
utility pvanal also implements PV analysis, producing PVOCEX-format spectral
ﬁles, which can be used with the streaming opcodes. A great variety of transforma-
tion techniques can be applied to PV data [75, 92].
14.4 The Phase Vocoder
311
Sliding phase vocoder
In the case of hopsizes that are smaller than the number of samples in a time-domain
processing block (ksmps), or if it is, is very small (≤10 samples), pvsanal will
switch to a special algorithm called the sliding phase vocoder [19]. This uses an it-
erative version of the DFT [18, 41], proposed originally by J. A. Moorer [94], which
uses the fact that if we use a hopsize-1 transform, there will be a lot of redundancy
between two consecutive analysis frames. The downside to this is that calculations
have to be made on a sample-by-sample basis, so the process can be quite heavy
on ordinary processors (although it is highly parallel, and has been implemented in
graphics processing units (GPUs) to take advantage of this.1
On the other hand, the sliding algorithm produces a smoother result, and as it
runs at the audio rate, it allows some processes to modulate the spectral data with an
audio signal. In listing 14.4, we have an example of this, where the input to the slid-
ing phase vocoder has its frequency modulated by an oscillator (using pvshift,
see Section 14.4.1 below), whose is locked in a 1:2.33 ratio with the pitch detected
in the input signal. Note that this code is unlikely to perform in real time (using
current CPU technology), but can be rendered to ﬁle output.
Listing 14.4 Sliding phase vocoder frequency modulation
instr 1
Sname = p5
p3 = filelen(Sname)
asig
diskin Sname
kcps,kamp ptrack asig, 1024
kcps port kcps,0.01
amod oscili p4*kcps,kcps*2.33
fs1 pvsanal asig,1024,1,1024,1
fs2 pvshift fs1,amod,0
ahr pvsynth fs2
out ahr
endin
schedule(1,0,0,5,"cornetto.wav")
14.4.1 Frequency Effects
The phase vocoder allows frequencies to be manipulated in a variety of ways. For
instance, we can scale it by a certain amount, which will result in pitch shifting. In
this case, all frequencies in a PV analysis frame get multiplied by a scalar value.
This is implemented by the pvscale opcode, which works with f-sigs:
1 Csound opcodes are available for this, but they require specialist hardware in the form of speciﬁc
GPU cards [69].
312
14 Spectral Processing
fsig
pvsanal fsigin,kscale
where kscale is the scaling value (pitch shift interval ratio), > 1 for upwards, and
< 1 for downwards transposition. This process is based on multiplying the frequency
data and then moving it to the correct bin, if necessary, as the scaling operation might
place the new frequencies beyond their original bin bandwidth. For wider scaling
with large transposition ratios, reducing the hopsize will improve the quality of the
effect. The pvscale process is alias-free: upwards transpositions do not introduce
frequencies beyond the Nyquist.
An alternative to pvscale is given by both the mincer and temposcal op-
codes. These opcodes read audio data from a function table and can pitch scale it,
producing an audio signal at the output. They employ a variant of the PV algorithm
that includes phase locking, which can reduce some of the artefacts that may appear
as a result of the process. Both opcodes transpose pitch using a different method to
pvscale, by resampling in the time domain prior to the PV analysis and synthesis.
Because of this, some care needs to be taken to avoid aliasing in upwards shift by
employing a ﬁlter (such as an FIR designed as per Section 13.4.3), if necessary.
These opcodes will be discussed in more detail in Section 14.4.5.
Another interesting PV effect is frequency shifting, which instead of scaling the
data, offsets it by a given amount. This causes the spectrum to either stretch or
compress, depending on the sign of the shift parameter. For instance, if we shift the
frequencies by 150 Hz, and the input signal has a harmonic spectrum with a 440 Hz
fundamental, the output partial frequencies will be 590, 1030, 1470,..., which make
up an inharmonic spectrum. Frequency shifting is implemented by
fsig pvshift fsigin, kshift, klowest
where kshift is the frequency offset, and klowest is the lowest frequency af-
fected by the process.
14.4.2 Formant Extraction
Pitch shifting of vocal sounds can suffer from a spectral distortion effect because all
the amplitudes also get shifted along with the frequencies. This is true of all forms
of the effect, regardless of how they are implemented. In order to ﬁx this, we need
to correct the amplitudes so that they are not distorted. This is done by extracting
the formants of the input sound. Formants are regions of resonance in the spectrum.
In the case of the voice, each different vowel sound will have characteristic for-
mants, which are more or less ﬁxed and do not change with fundamental frequency.
When pitch shifting, these are also transposed, causing a noticeable distortion in the
spectrum (the ‘Donald Duck’ effect). We call the overall contour of the amplitude
spectrum the spectral envelope. Formants are ‘bumps’ or ‘mountains’ in the spec-
tral envelope, each one with a speciﬁc centre frequency and bandwidth. The channel
vocoder discussed in Section 12.2 depends on the presence of clear formant regions
for its effect clarity.
14.4 The Phase Vocoder
313
Both pvscale and pvshift have optional working modes where formants are
extracted and reapplied to the transposed sound, correcting the distortion caused by
the frequency changes. These are particularly important if we want to create realistic
harmonisation or pitch correction effects:
fsig pvsanal fsigin,kscale,ikeepform
fsig pvshift fsigin, kshift, klowest,ikeepform
There are three options for ikeepform: 0 for no effect, 1 selects plain cepstrum
processing and 2 uses the true envelope method. Mode 1 is the least computation-
ally expensive and generally performs well. Listing 14.5 shows a harmoniser using
pvscale and formant correction. Note how we need to use a delay line to time
align the direct and PV signals, as the PV imposes a small latency of N +h samples,
where N is the DFT size and h the hopsize.
Listing 14.5 Harmoniser example, with formant correction
instr 1
isiz = 2048
Sf = "cornetto.wav"
p3 = filelen(Sf)
asig diskin2 Sf,1
fs1 pvsanal asig,isiz,isiz/8,isiz,1
fs2 pvscale fs1,p4,1
ahr pvsynth fs2
adi delay
asig,isiz*1.125/sr
out ahr*p6+adi*p5
endin
schedule(1,0,1,1.25,0.75,0.75)
schedule(1,0,1,.75,0,0.75)
The cepstrum is another important tool in frequency-domain processing. It is
deﬁned as the DFT of the log magnitude spectrum. It detects the undulations in
the amplitudes of a DFT frame, where the wider ones will correspond to low-index
cepstral coefﬁcients and the narrower ones to high-index ones. If we think of the
magnitude spectrum as a waveform, then we can visualise how this is the case: long
ﬂuctuations appear in the low part of the spectrum, short ones are to do with high
frequencies.
Formants are detected by removing the narrow undulations in the amplitude spec-
trum, and keeping the wider ones that deﬁne resonance regions. With the cepstrum
we can do this by liftering (removing) the high-order coefﬁcients, then taking the
inverse cepstrum to recover the spectral envelope with the formant regions. A plot
demonstrating this result is shown in Fig. 14.11, where we can see a formant curve
that has been obtained from an underlying spectrum using the cepstrum method.
Once we have this, we can apply it to shape the amplitudes of the transposed signal.
The spectral envelope can also be manipulated independently of the frequencies,
in case we want to deliberately distort it to change the character of an input sound.
The pvswarp opcode is designed to do this:
314
14 Spectral Processing
Fig. 14.11 The spectral envelope (thick line), obtained using the cepstrum method, and its under-
lying amplitude spectrum
fsig pvswarp fsigin, kscal, kshift
where kscal scales the spectral envelope, stretching (> 1) or compressing it (< 1),
and kshift shifts it linearly by a certain offset (positive or negative).
14.4.3 Spectral Filters
It is possible to manipulate the amplitudes in the PV stream fairly freely. This allows
us to construct time-varying ﬁlters, which will shape the spectrum in some way.
There are a number of opcodes in Csound that allow f-sigs to be ﬁltered. The ﬁrst
of these is a pair of band-pass and band-reject ﬁlters:
fsig pvsbandp fsigin, xlowcut, xlowfull,
xhighfull, xhighcut[,ktype]
fsig pvsbandr fsigin, xlowcut, xlowfull,
xhighfull, xhighcut[,ktype]
These ﬁlters pass or reject a certain trapezoid-shaped band in the spectrum, de-
ﬁned by xlowcut, xlowfull, xhighfull and xhighcut. The ﬁrst two pa-
rameters determine the lower transition, and the other two, the higher transition
bands, in Hz. These parameters are normally k-rate, but can work at audio rate if
hopsize 1 is used. The optional ktype parameter can be used to determine the
shape of the transition curve (defaults to linear). More generally, we can draw any
shape on a function table and use it as the amplitude curve of a ﬁlter that is applied
with
fsig pvsmaska fsrc, ifn, kdepth
Here, the function table ifn should have at least N
2 +1 points (one for each bin),
with an arbitrary shape that will be used to ﬁlter fsrc. The amount of ﬁltering ca
be controlled dynamically with kdepth.
14.4 The Phase Vocoder
315
We can also use an arbitrary PV stream to ﬁlter another. This is very similar to
the previous case, but now we are using an fsig as the (time-varying) amplitude
curve for the ﬁlter. This is a generalisation of the idea of ﬁltering, and the result is
an emphasis on the common spectral elements between the two PV streams used
(input and ﬁlter):
fsig pvsfilter fsigin, fsigfil, kdepth[, igain]
where fsigfil is the ‘ﬁlter’ used. For instance, a sine wave would work as a very
narrow band-pass ﬁlter. Other, arbitrary, time-varying signals will have a variety of
effects, making this process a rich ﬁeld for continuous experimentation.
Another type of ﬁltering that is possible to do with the phase vocoder is sten-
cilling. This is done by comparing one signal to a mask, bin-per-bin, and changing
its amplitude if it falls below that of the mask:
fsig pvstencil fsigin, kgain, klevel, ifn
The mask is provided by the function table ifn, with at least N
2 points. If the
amplitude of a bin falls below the mask multiplied by klevel, then it is scaled
by kgain. For noise reduction applications, a noise print function table can be
created with GEN43. This reads PV data from a ﬁle and creates a single frame of
amplitudes containing their average over the duration of the sound. However, the
mask function table can be created with any arbitrary means for different types of
amplitude transformation. The kgain parameter can also be set to > 1 for reverse-
masking effects.
14.4.4 Cross-synthesis and Morphing
The discussion of ﬁltering in the previous section touched on an important point for
PV processing: the possibility of combining the characteristics of two spectra. This
is generally called cross-synthesis, and there are a number of ways in which it can
be achieved (including some of the ﬁltering operations above). The ﬁrst one of these
is a straight combination of amplitudes from one PV stream with the frequencies of
another:
fsig pvscross fsrc, fdest, kamp1, kamp2
In this case, depending on the values for kamp1 and kamp2, the output signal
will have the frequencies of fsrc and a mix of the amplitudes of fsrc and fdest.
If kamp2 = 0, no cross-synthesis will take place, and if kamp1 = 0, then only the
fdest amplitudes will be used (provided that kamp2 is not zero).
A similar operation is provided by pvsvoc, but instead of the raw bin ampli-
tudes, we apply the spectral envelope of one stream to the frequencies of another.
The difference between the two can be appreciated in Fig. 14.11.
fsig pvsvoc famp, fexc, kdepth, kgain
316
14 Spectral Processing
Here, with kdepth = 1, the spectral envelope of famp will be combined with
the frequencies of fexc. With lower kdepth values, less of the fexc signal is
used. This opcode can produce results that are similar to the channel vocoder, but
with a different character.
Finally, the pvsmorph opcode implements spectral interpolation of amplitudes
and frequencies. Two signals are combined depending on the value of the interpola-
tion parameters:
fsig pvsmorph fsig1, fsig2, kampint, kfrqint
The kampint and kfrqint arguments control linear amplitude and frequency
interpolation, where 0 corresponds to fsig1 and 1 to fsig2. In between these
two values, it is possible to morph the two spectra. The seamlessness of the inter-
polation will depend on the similarity of the two inputs. If they have spectra whose
components are not in overlapping regions, the effect of changing the interpolation
parameters over time might sound more like a cross-fade. If, however, they have
good correspondences in terms of their partials, the effect can be quite striking. A
simple UDO demonstrating this application is shown in listing 14.6, where the spec-
tra of two signals can be interpolated independently in amplitude and frequency.
Listing 14.6 Morphing UDO
/**************************************************
asig Morph ain1,ain2,kaint,kfint
ain1 - input signal 1
ain2 - input signal 2
kaint - amplitude interpolation (0 < kaint < 1)
kaint - frequency interpolation (0 < kfint < 1)
**************************************************/
opcode Morph,a,aakk
as1,as2,ka,kf xin
isiz = 2048
ihop = isiz/8
fs1 pvsanal as1,isiz,ihop,isiz,1
fs2 pvsanal as2,isiz,ihop,isiz,1
fsm pvsmorph fs1,fs2,ka,kf
xout pvsynth(fsm)
endop
14.4.5 Timescaling
Timescaling is the effect of changing the duration of an audio signal without af-
fecting its frequencies. As we know from the previous chapters, by reading a sound
from a function table or a delay line at a speed that is different than the one we
originally used to write the data we can change its pitch. With the phase vocoder,
14.4 The Phase Vocoder
317
we have already seen that the pitch of the signal can be manipulated independently.
It turns out that its duration can also be changed.
Pure timescaling is an inherently non-real-time operation. Although we can play
back sounds and modify their durations on the ﬂy, we need to have these stored
somewhere previously (as we cannot predict the future or have inﬁnite memory for
past events). It is possible to record audio into a memory buffer, and then play it
back at a different rate, but eventually we will either run out of input signal (if we
compress the durations) or run out of memory (if we stretch them).
The PV process can stretch or compress audio data by playing it back at a dif-
ferent rate than it was written. Since what it uses is a series of amplitude-frequency
frames, when the data is synthesised, it will not have its frequencies altered (unless
we do so explicitly). Time and frequency are bundled together in a waveform. If we
change one, we also modify the other. In the spectral domain, however, we can break
the ties that link them together. A PV frame is a full description of a segment of a
waveform. The playback rate of PV frames does not change this fact, and so, in gen-
eral, a sound can have its duration modiﬁed without affecting its frequencies (within
certain bounds, as some audible artefacts might appear in extreme stretching).
Timescaling is done by reading through a sequence of audio frames at different
rates. This can mean repeating, or interpolating between, frames for stretching, and
skipping frames for compression. The two function-table-reading opcodes mincer
and temposcal both implement this process internally, doing a full analysis-
synthesis cycle to produce a timescaled (and independently pitch-transposed) out-
put. They implement a technique called phase locking that can reduce the artefacts
found in extreme time stretching:
asig mincer atimpt, kamp, kpitch, ktab,
klock[,ifftsize,idecim]
This opcode takes an audio-rate time position in secs (atimpnt) and plays the
audio from function table ktab at that point. To make the sound play back at the
original rate, we need to increment the time position linearly without scaling it. It
is possible to go backwards and to scratch back and forth, or to freeze the sound at
given points. There is total time ﬂexibility with this opcode, and the pitch can be
transposed independently. The parameter klock switches phase locking on or off,
and we can control the DFT and hop size by changing the default parameters (2048
and 256, respectively):
asig temposcal ktimescal, kamp, kpitch, ktab,
klock [,ifftsize, idecim, ithresh]
The temposcal opcode is a variation, which plays back the audio according
to a timescaling parameter, 1 for no change, below 1 for stretching and above 1
for compression (like a speed control). In addition, it attempts to ﬁnd attack tran-
sients in the audio so that these are not stretched (the time stretching is momentarily
suppressed). This allows a better result in scaling the tempo of recordings, so that
hits and note onsets are not smeared (Fig. 14.12). This is done by comparing the
power of the audio in subsequent frames, looking for abrupt changes that might
318
14 Spectral Processing
indicate attacks. The optional ithresh parameter can be used to change the de-
tection threshold (1 dB).
Fig. 14.12 A xylophone strike (top) and two time-stretched versions (10 x original duration). The
middle one shows a clear smearing of the note onset, whereas the bottom one preserves the onset
(produced by temposcal)
It is also possible to timescale streaming PV signals. We can do this by either
reading from a table or a ﬁle, or by writing and reading from a memory buffer. In
the ﬁrst case, the opcode pvstanal is a variant on temposcal that produces
fsigs as output. It has similar parameters and behaviour, with the exception that it
does not perform phase locking, as this is not available for PV streams.
Phase vocoder data ﬁles can be generated with the utility pvsanal. This can
be accessed via a dedicated menu option in some frontends (e.g. CsoundQt), and is
available through the -U pvsanal command option:
csound -U pvsanal <input> <output.pvx> <options>
where <input> is the name of an input ﬁle in any of the formats accepted by
Csound, and <output.pvx> is a ﬁle containing the PV data, which uses the special
PVOCEX format. This is the PV ﬁle format used throughout Csound. A number
of optional parameters (<options>) can be used to control the analysis. Details on
14.4 The Phase Vocoder
319
these can be found in the Reference Manual. Such PV analysis ﬁles can be read
using the opcodes
fsig pvsfread ktimpt, Sname [, ichan]
fsig pvsdiskin Sname,ktscal,kgain[,ioffset, ichan]
The difference between them is that the ﬁrst one loads the whole ﬁle into memory
and reads from there. The second one reads directly from the disk. Their parame-
ters are also slightly different, with pvsfread using a time position to read from
the ﬁle (ktimpt), and pvsdiskin using a timescaling factor (ktscal). In both
opcodes, Sname is a string containing the name of the PVOCEX analysis ﬁle. They
will output a PV stream that can be used with other opcodes, and synthesised with
pvsynth. These opcodes use interpolation for timescaling, so the resulting out-
put is somewhat different from mincer and temposcal. In addition, there is
no phase locking of PV streams, so artefacts might result in very long stretching.
However, these can also be explored creatively in the design of new sounds.
Finally, there are a pair of opcodes that set up a memory buffer write/read scheme
for PV streams. These are
ihandle, ktime
pvsbuffer fsig, ilen
fsig pvsbufread
ktime, khandle
The ﬁrst opcode sets up a circular buffer ilen seconds long and writes fsig to
it. Its outputs are a reference to the circular buffer (ihandle) and the current write
time position into the buffer. The reading opcode reads from the buffer referred to
by khandle, at ktime, producing fsig. Note that its time position is completely
independent from the write time, and that it can be decremented (for backwards
playback). Any number of readers can refer to one single circular buffer (single
writer, many readers). The writing ktime can be used as an indicator of the current
time for the readers.
It is important to point out that as the buffer memory is ﬁnite, time compressing
will eventually make the reader go beyond the range of the buffer, and also overtake
the writing position. Time stretching can cause the writing to overtake the reading
position. In both cases, the results will depend on the input sound. In any case,
reading wraps around the ends of the buffer, in both directions. These opcodes can
be used for a range of different real-time PV stream time manipulations.
14.4.6 Spectral Delays
The pvsbuffer opcode can also be thought of as a spectral delay line, with any
number of taps implemented by pvsbufread. In addition, the reading can be done
in speciﬁc frequency bands, so different delay times can be set for different areas
of the spectrum. This is enabled by two optional arguments, ilo and ihi, which
deﬁne the frequency band to be read:
fsig pvsbufread
ktime, khandle[, ilo, ihi]
320
14 Spectral Processing
This characteristic is further enhanced by pvsbufread2, which allows the user
to set a per-bin delay time for amplitudes and frequencies, independently. Thus with
a single opcode, multiple delay times can be achieved for different spectral bands,
down to a bin bandwidth resolution:
fsig pvsbufread2
ktime, khandle, ift1, ift2
The function tables ift1 and ift2 contain the delay times in seconds for each
one of the bins, for amplitude and frequency, respectively. They should be at least
N
2 +1 positions long. These opcodes can be used to create many effects where delays
are attached to different areas of the spectrum, de-synchronising the PV stream.
Listing 14.7 shows the effect applied to the viola sound of Fig. 14.6. Its spectrogram
is shown in Fig. 14.13. Note how the function table is used to delay frequencies in
ascending order from bin 0 to 128 (5,512.5 Hz).
Listing 14.7 Spectral delay example
ifn ftgen 1,0,514,7,0,128,1,256,1,128,1
instr 1
Sf = "violac3.wav"
p3 = filelen(Sf)
a1 diskin2 Sf,1
fs1 pvsanal a1,1024,128,1024,1
ih,kt pvsbuffer fs1, 2
fs2 pvsbufread2 kt,ih,1,1
a2 pvsynth fs2
out a2
endin
schedule(1,0,1)
Fig. 14.13 The C4 viola sound (Fig. 14.6) played through a spectral delay with delay times that
increase with frequency. It is possible to see how it makes the harmonics arpeggiate as their onset
is spread out in time
14.5 Sinusoidal Modelling
321
14.4.7 Miscellaneous Effects
A number of non-standard frequency data manipulation effects can be applied to PV
streams:
•
Spectral arpeggios: the pvsarp opcode transforms the amplitudes of an input
PV stream by boosting one bin and attenuating all the others around it. It can be
used with an LFO to create partial arpeggiation effects.
•
Blurring: a PV stream can be blurred by averaging out its amplitude and fre-
quency over time using pvsblur.
•
Demixing: pvsdemix takes a stereo signal and attempts to extract mixed
sources by searching positions using a reverse pan pot.
•
Freezing: it is possible to freeze an input signal at a given point using pvsfreeze.
•
Mixing: the pvsmix opcode can be used to do an ultra-seamless mix by com-
bining the loudest bins from two different inputs.
•
Smoothing: the frequency and amplitude parts of a PV stream can be smoothed
with a ﬁrst-order low-pass ﬁlter through the use of pvsmooth.
•
Signal generation: pvsosc produces a variety of audio waveforms directly in
the spectral domain.
In addition to these, PV streams can be written and read to/from tables via
the pvsftw and pvsftr opcodes, and to/from arrays with pvs2array and
pvsfromarray. The pitch of a signal can be tracked with pvspitch, as well
as its centroid, with pvscent. We can read individual bins with pvsbin, and dis-
play the data using pvsdisp (this will also depend on frontend implementation).
The streaming phase vocoder subsystem in Csound is a rich source of opportunities
for the exploration of spectral manipulation of audio.
14.5 Sinusoidal Modelling
Another approach to spectral processing is to model a sound as a sum of time-
varying sinusoidal tracks [74, 9].This, in contrast to the DFT-frame approach of the
phase vocoder, will identify peaks in the spectrum, over a certain time, and link
them to make continuous lines. Each one of these will be modelling a sinusoid, with
a variable amplitude, frequency and phase [85]. So, for instance, while in PV anal-
ysis a single-component glissando would be detected at various bins in successive
frames, here it will create a single track.
The spectral data, in this case, is a collection of tracks. These can be provided
as part of a streaming process in the same way as in the phase vocoder. However,
the number of tracks will be variable, as some can die off, and new ones can appear
as the sound changes over time. The most common way of reconstructing the time-
domain audio signal from these is to use additive synthesis. One of the advantages
of the sinusoidal method is that it is possible to keep the phase information intact
322
14 Spectral Processing
while resynthesising, which is not the case with the phase vocoder, where phases
are discarded.
The central component of sinusoidal modelling is partial tracking. This is done
by ﬁrst searching for peaks in the spectrum, determining their position and then
matching them with previously detected ones in an earlier time point. The process
is done successively in time, spaced by a hopsize. So a track will emerge from a
peak, and if a continuation is found at the following time point, it will be kept. This
is done until no connection is found, and the track is killed. Tracks are linked by
frequency and amplitude proximity. If too much of a change is found in either, two
peaks will not be connected as a track. The analysis can require a number of points
to exist before a track is allowed to exist, as well as small gaps in its continuation.
A plot of a series of frequency tracks of a piano sound is shown in Fig. 14.14.
Fig. 14.14 Partial frequencies of a piano note recording as tracked by a sinusoidal model. Ampli-
tudes are shown in grey scale (set according to the maximum amplitude of each track)
Csound provides a suite of streaming sinusoidal modelling opcodes, for analysis
transformation, and synthesis. The process of creating the sinusoidal tracks can be
outlined as follows: